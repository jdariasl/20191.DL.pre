# 20191.DL Fundamentos de Deep Learning

## Calendario

    W01  5feb      Intro.Class                        Intro.ML   
    W02 12feb      U1.Intro.NN                        Lab 1.1
    W03 19feb      U2.NN.Archs.TrainAlgs.Reg          Lab 2.1
    W04 26feb      U2.NN.Initz.Batch.Relu.Vanish      Lab 2.2
    W05  5mar      Labs                               Parcial         10Mar Deadline Lab1 Lab2
    W06 12mar      U3.CNN.ConvOp.Archs                Lab 3.1
    W07 19mar      U3.CNN.Classf.Detectn.Segmtn       Lab 3.2         31Mar Deadline U3.05 3.06 3.07 3.10 3.11
    W08 26mar      U3.CNN.Transfer Learning           Lab 3.3         7abr Deadline U3.15 3.16 3.17
    W09  2abr      U3.Proyecto                        U3.Proyecto
    W10  9abr      U3.Proyecto                        U3.Proyecto     21Abr Deadline U3.Proyecto
    W11 23abr      U4.RNN.SeqModels.BProp in Time     Lab 4.1         25Abr presentación proyectos seleccionados
    W12 30abr      U4.RNN.LSTM.Archs.Seq2Seq          Lab 4.2
    W13  7may      U4.RNN.CNN-LSTM                    Lab 4.3         12May Deadline Lab4
    W14 14may      U4.Proyecto                        U4.Proyecto
    W15 21may      U4.Proyecto                        U4.Proyecto
    W16 28may                                                         01Jul Deadline U4.Proyecto
    
 ## Evaluación
 
     10% Parcial
     10% Lab1 + Lab 2
     15% Lab 3
     15% Lab 4
     25% U3.Proyecto
     25% U4.Proyecto
     
## Proyectos

Para el proyecto U3 (redes convolucionales) y U4 (redes recurrentes) tendrás que:

- escoger un dataset, de un tema de tu interés, de tu investigación, etc.
- plantear una tarea de aprendizaje junto con una métrica de evaluación (p.ej. clasificación, detección, etc.)
- plantear una estrategia de resolución (preprocesado, arquitectura de red, trasnfer learning, data augmentation, feature learning, etc.)
- implementar el flujo de trabajo experimental

### Entrega

Tu entrega habrá de ser **un repositorio github** con uno o varios notebooks donde proveas evidencia del trabajo realizado, incluyendo experimentos pruebas, etc.

**Para realizar tu entrega**, crea un documento llamado `U3.Proyecto` o `U4.Proyecto` en el Google drive compartido, que contenga el enlace a tu repositorio github. Si llamas distinto a este documento **no será tenido en cuenta**.

### Criterios de evaluación

- **25% Reproducibilidad**: Tus notebooks han de ser 100% ejecutables sin errores, desde la descarga de datos hasta la obtención de tus resultados. Si lo consideras necesario crea un fichero descargable con tus datos y publícalo en algún lado como están en los notebooks del curso. **No incluyas los datos en el repositorio**.
- **25% Claridad**: Explica bien tu tarea (en los mismos notebooks), la métrica de evaluación que ests usando y el ciclo experimental que hiciste (probé tales arquitecturas de red, el modelo final tiene tal arquitectura porque las anteriores sufrían de overfitting, etc.) 
- **25% Repositorio**: Tu repositorio ha de estar ordenado, con una estructura clara y con un README.md que indique qué notebooks ejecutar con tu resultado final, qué notebooks contienen los experimentos previos que hiciste, etc.
- **25% Compleción**: Tu tarea ha de utilizar las técnicas vistas en clase y ha de demostrar un flujo experimental (prueba de varias arquitecturas, preprocesados, etc.). Igualmente has de incluir una **interpretación de tus resultados**.

### Presentación

Si se te requiere tendrás que realizar una **breve presentación** de tu proyecto, teniendo en cuenta que:

- la presentacin ha de durar **10 minutos**. Esto es un límite **estricto**. Al cabo de ese tiempo se cortará la presentación esté en el punto que esté.
- Tendrás que presentar **tres aspectos**: 1) qué tarea se resolvió, 2) qué experimentos se hicieron, 3) tus conclusiones e interpretación de los resultados.
- La calificación será **un factor entre 0.5 y 1.5**, que se multiplicará con la calificación obtenida a la entrega para obtener la calificación final.



 ## Registro y materiales
 
 - [Listado de estudiantes](https://docs.google.com/spreadsheets/d/1jbCc0ZHC5qFMhwMEpoCgSFzHwP6lx_V77E4Blh6Tk38/edit#gid=2001230691)
 - [Máquina virtual del curso](https://drive.google.com/file/d/1VI5oU_gQQ0LO_Eoiq8N66j1zgi8-vC6j/view?usp=sharing)
 

## Lecturas recomendadas

- Hastie, Tibshirani, Friedman, **The Elements of Statistical Learning**, Springer-Verlag [website](https://web.stanford.edu/~hastie/ElemStatLearn/) [pdf](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)
- Goodfellow, Bengio, Courville, **Deep Learning**, MIT Press [website](https://www.deeplearningbook.org/) [pdf](https://github.com/janishar/mit-deep-learning-book-pdf)
- Bengio, **Learning Deep Architectures for AI**, Foundations and Trends in
Machine Learning, Vol. 2, No. 1 (2009) 1–127, [pdf](http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf)
